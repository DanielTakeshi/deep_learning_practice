Some notes and reminders to myself about TF:

It uses symbolic computations. Don't assume normal Python variables. The purpose
is to use potentially complicated expressions and math formulas and encode it
into a "dataflow" graph, which is then offloaded to a Tensorflow "Session" which
can efficiently execute the entire computation. For instance, with
backpropagation, it uses symbolic differentiation. I hope it's basically a C++
version of what we did in CS 294-129 at Berkeley.

Feeding, use feed_dict as input to Sessions so that Tensors can be turned into
numpy arrays. Closely related to these are tf.placeholder()s, which _must_ be
fed with some data. Recall that the feed_dict has tf.placeholder()s as
dictionary arguments.

Tensorboard -- hopefully I can use this. I'll update these notes later.

Custom format data -- see the FAQ. Hopefully this will work and I can update
these notes.
